{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# CLEAN FOLDERS - IMPORT DATA - RENAME FOLDERS - PRINT DB STRUCTURE.\n"
      ],
      "metadata": {
        "id": "5cg9I9C3R3aR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# BLOCK 0: Clean Dataset Folder\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "def cleanup_dataset():\n",
        "    \"\"\"\n",
        "    Remove existing dataset folder to start fresh\n",
        "    \"\"\"\n",
        "    dataset_path = '/content/dataset'\n",
        "\n",
        "    if os.path.exists(dataset_path):\n",
        "        print(\"Removing existing dataset folder...\")\n",
        "        shutil.rmtree(dataset_path)\n",
        "        print(\"Dataset folder cleaned!\")\n",
        "    else:\n",
        "        print(\"No existing dataset folder found\")\n",
        "\n",
        "    # Also remove any leftover zip file\n",
        "    zip_path = '/content/dataset.zip'\n",
        "    if os.path.exists(zip_path):\n",
        "        os.remove(zip_path)\n",
        "        print(\"Removed old dataset.zip\")\n",
        "\n",
        "    print(\"Ready for fresh import!\")\n",
        "\n",
        "# Run cleanup\n",
        "cleanup_dataset()"
      ],
      "metadata": {
        "id": "9VZ2Gx2ju5bB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FcSGsRnfdTmF"
      },
      "outputs": [],
      "source": [
        "import gdown\n",
        "import zipfile\n",
        "\n",
        "# Your Google Drive sharing link\n",
        "# https://drive.google.com/file/d/1pfyAN5XE4ULgnx9NHfMCgw9QK6KCee_l/view?usp=sharing\n",
        "\n",
        "# Extract the file ID from the link\n",
        "file_id = '1pfyAN5XE4ULgnx9NHfMCgw9QK6KCee_l'\n",
        "url = f'https://drive.google.com/uc?id={file_id}'\n",
        "\n",
        "print(\"Downloading dataset from Google Drive...\")\n",
        "output_path = '/content/dataset.zip'\n",
        "\n",
        "# Download the file\n",
        "gdown.download(url, output_path, quiet=False)\n",
        "\n",
        "# Extract the dataset\n",
        "print(\"Extracting dataset...\")\n",
        "with zipfile.ZipFile(output_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/dataset')\n",
        "\n",
        "print(\"Dataset downloaded and extracted successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from torchvision.datasets import ImageFolder # Import ImageFolder\n",
        "\n",
        "# Rename folders to remove spaces\n",
        "train_old = '/content/dataset/content/bone_data/train/not fractured'\n",
        "train_new = '/content/dataset/content/bone_data/train/normal' # Corrected path\n",
        "val_old = '/content/dataset/content/bone_data/val/not fractured'\n",
        "val_new = '/content/dataset/content/bone_data/val/normal' # Corrected path\n",
        "\n",
        "# Rename train folder\n",
        "if os.path.exists(train_old):\n",
        "    os.rename(train_old, train_new)\n",
        "    print(\"Renamed train/not fractured -> train/normal\")\n",
        "\n",
        "# Rename val folder\n",
        "if os.path.exists(val_old):\n",
        "    os.rename(val_old, val_new)\n",
        "    print(\"Renamed val/not fractured -> val/normal\")\n",
        "\n",
        "print(\"Folder renaming complete!\")\n",
        "\n",
        "# Verify the new structure\n",
        "train_dataset_test = ImageFolder('/content/dataset/content/bone_data/train') # Corrected path\n",
        "print(f\"Classes after renaming: {train_dataset_test.classes}\")"
      ],
      "metadata": {
        "id": "lS8QfEvgi67G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add this block to check your dataset structure\n",
        "import os\n",
        "print(\"Dataset structure:\")\n",
        "for root, dirs, files in os.walk('/content/dataset'):\n",
        "    level = root.replace('/content/dataset', '').count(os.sep)\n",
        "    indent = ' ' * 2 * level\n",
        "    print(f'{indent}{os.path.basename(root)}/')\n",
        "    subindent = ' ' * 2 * (level + 1)\n",
        "    for file in files[:3]:  # Show first 3 files\n",
        "        print(f'{subindent}{file}')\n",
        "    if len(files) > 3:\n",
        "        print(f'{subindent}... and {len(files)-3} more files')"
      ],
      "metadata": {
        "id": "2YiPjKO3iiWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DATA AUGMENTATION\n",
        "======================================================\n",
        "Change Flag True or False to enable data augmentation\n",
        "======================================================"
      ],
      "metadata": {
        "id": "c4eAG6PNR363"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# BLOCK: Data Augmentation Configuration\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Toggle this flag to enable/disable augmentation\n",
        "USE_AUGMENTATION = True  # Set to False to disable augmentation\n",
        "\n",
        "print(f\"Data Augmentation: {'ENABLED' if USE_AUGMENTATION else 'DISABLED'}\")\n",
        "\n",
        "if USE_AUGMENTATION:\n",
        "    # WITH Data Augmentation\n",
        "    train_transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.RandomHorizontalFlip(p=0.5),\n",
        "        transforms.RandomRotation(10),\n",
        "        transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "    print(\"Using augmented training transforms:\")\n",
        "    print(\"- Random horizontal flip (50%)\")\n",
        "    print(\"- Random rotation (Â±10Â°)\")\n",
        "    print(\"- Color jitter (brightness & contrast Â±20%)\")\n",
        "\n",
        "else:\n",
        "    # WITHOUT Data Augmentation (same as validation)\n",
        "    train_transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "    print(\"Using basic training transforms (no augmentation)\")\n",
        "\n",
        "# Validation transform (always the same - no augmentation)\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "print(\"Validation/Test transforms: Basic resize + normalize only\")\n",
        "print(\"=\" * 50)"
      ],
      "metadata": {
        "id": "rl9IkLm_nkZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MODEL COMPARISON"
      ],
      "metadata": {
        "id": "e_2QaKRLUkoP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "from torchvision.datasets import ImageFolder\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "import os\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "\n",
        "# Check if CUDA is available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Simple CNN Architecture\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self, num_classes=2):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "\n",
        "        self.features = nn.Sequential(\n",
        "            # First Conv Block\n",
        "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "\n",
        "            # Second Conv Block\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "\n",
        "            # Third Conv Block\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "\n",
        "            # Fourth Conv Block\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d((7, 7)),\n",
        "            nn.Flatten(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256 * 7 * 7, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "# Function to create ResNet model\n",
        "def create_resnet(num_classes=2, pretrained=True):\n",
        "    model = models.resnet50(pretrained=pretrained)\n",
        "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "    return model\n",
        "\n",
        "# Function to create EfficientNet model\n",
        "def create_efficientnet(num_classes=2, pretrained=True):\n",
        "    model = models.efficientnet_b0(pretrained=pretrained)\n",
        "    model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
        "    return model\n",
        "\n",
        "# Training function\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    model = model.to(device)\n",
        "\n",
        "    train_losses = []\n",
        "    train_accuracies = []\n",
        "    val_losses = []\n",
        "    val_accuracies = []\n",
        "\n",
        "\n",
        "    best_val_acc = 0.0\n",
        "    best_model_wts = model.state_dict().copy()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'\\nEpoch {epoch+1}/{num_epochs}')\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "        total_samples = 0\n",
        "\n",
        "        pbar = tqdm(train_loader, desc='Training')\n",
        "        for inputs, labels in pbar:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            running_corrects += torch.sum(preds == labels.data)\n",
        "            total_samples += inputs.size(0)\n",
        "\n",
        "            pbar.set_postfix({'Loss': f'{loss.item():.4f}'})\n",
        "\n",
        "        epoch_train_loss = running_loss / total_samples\n",
        "        epoch_train_acc = running_corrects.double() / total_samples\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        val_running_loss = 0.0\n",
        "        val_running_corrects = 0\n",
        "        val_total_samples = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in tqdm(val_loader, desc='Validation'):\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                val_running_loss += loss.item() * inputs.size(0)\n",
        "                val_running_corrects += torch.sum(preds == labels.data)\n",
        "                val_total_samples += inputs.size(0)\n",
        "\n",
        "        epoch_val_loss = val_running_loss / val_total_samples\n",
        "        epoch_val_acc = val_running_corrects.double() / val_total_samples\n",
        "\n",
        "        train_losses.append(epoch_train_loss)\n",
        "        train_accuracies.append(epoch_train_acc.cpu().numpy())\n",
        "        val_losses.append(epoch_val_loss)\n",
        "        val_accuracies.append(epoch_val_acc.cpu().numpy())\n",
        "\n",
        "        print(f'Train Loss: {epoch_train_loss:.4f} Acc: {epoch_train_acc:.4f}')\n",
        "        print(f'Val Loss: {epoch_val_loss:.4f} Acc: {epoch_val_acc:.4f}')\n",
        "\n",
        "        # Save best model\n",
        "        if epoch_val_acc > best_val_acc:\n",
        "            best_val_acc = epoch_val_acc\n",
        "            best_model_wts = model.state_dict().copy()\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "    # Load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "\n",
        "    return model, {\n",
        "        'train_losses': train_losses,\n",
        "        'train_accuracies': train_accuracies,\n",
        "        'val_losses': val_losses,\n",
        "        'val_accuracies': val_accuracies,\n",
        "        'best_val_acc': best_val_acc.cpu().numpy()\n",
        "    }\n",
        "\n",
        "# Evaluation function\n",
        "def evaluate_model(model, test_loader, class_names):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm(test_loader, desc='Testing'):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = np.mean(np.array(all_preds) == np.array(all_labels))\n",
        "\n",
        "    # Classification report\n",
        "    report = classification_report(all_labels, all_preds,\n",
        "                                 target_names=class_names,\n",
        "                                 output_dict=True)\n",
        "\n",
        "    # Confusion matrix\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "\n",
        "    return accuracy, report, cm, all_preds, all_labels\n",
        "\n",
        "# Plotting functions\n",
        "def plot_training_history(histories, model_names):\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "    # Training Loss\n",
        "    axes[0, 0].set_title('Training Loss')\n",
        "    for i, (history, name) in enumerate(zip(histories, model_names)):\n",
        "        axes[0, 0].plot(history['train_losses'], label=name)\n",
        "    axes[0, 0].set_xlabel('Epoch')\n",
        "    axes[0, 0].set_ylabel('Loss')\n",
        "    axes[0, 0].legend()\n",
        "    axes[0, 0].grid(True)\n",
        "\n",
        "    # Validation Loss\n",
        "    axes[0, 1].set_title('Validation Loss')\n",
        "    for i, (history, name) in enumerate(zip(histories, model_names)):\n",
        "        axes[0, 1].plot(history['val_losses'], label=name)\n",
        "    axes[0, 1].set_xlabel('Epoch')\n",
        "    axes[0, 1].set_ylabel('Loss')\n",
        "    axes[0, 1].legend()\n",
        "    axes[0, 1].grid(True)\n",
        "\n",
        "    # Training Accuracy\n",
        "    axes[1, 0].set_title('Training Accuracy')\n",
        "    for i, (history, name) in enumerate(zip(histories, model_names)):\n",
        "        axes[1, 0].plot(history['train_accuracies'], label=name)\n",
        "    axes[1, 0].set_xlabel('Epoch')\n",
        "    axes[1, 0].set_ylabel('Accuracy')\n",
        "    axes[1, 0].legend()\n",
        "    axes[1, 0].grid(True)\n",
        "\n",
        "    # Validation Accuracy\n",
        "    axes[1, 1].set_title('Validation Accuracy')\n",
        "    for i, (history, name) in enumerate(zip(histories, model_names)):\n",
        "        axes[1, 1].plot(history['val_accuracies'], label=name)\n",
        "    axes[1, 1].set_xlabel('Epoch')\n",
        "    axes[1, 1].set_ylabel('Accuracy')\n",
        "    axes[1, 1].legend()\n",
        "    axes[1, 1].grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def plot_confusion_matrices(cms, model_names, class_names):\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
        "\n",
        "    for i, (cm, name) in enumerate(zip(cms, model_names)):\n",
        "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                   xticklabels=class_names, yticklabels=class_names, ax=axes[i])\n",
        "        axes[i].set_title(f'{name} - Confusion Matrix')\n",
        "        axes[i].set_xlabel('Predicted')\n",
        "        axes[i].set_ylabel('Actual')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Main execution function\n",
        "def main():\n",
        "    # Expected structure:\n",
        "    # dataset/\n",
        "    #   â”œâ”€â”€ train/\n",
        "    #   â”‚   â”œâ”€â”€ fractured/\n",
        "    #   â”‚   â””â”€â”€ normal/\n",
        "    #   â””â”€â”€ val/\n",
        "    #       â”œâ”€â”€ fractured/\n",
        "    #       â””â”€â”€ normal/\n",
        "\n",
        "    data_dir = '/content/dataset/content/bone_data'\n",
        "\n",
        "    # Create datasets\n",
        "    train_dataset = ImageFolder(os.path.join(data_dir, 'train'), transform=train_transform)\n",
        "    val_dataset = ImageFolder(os.path.join(data_dir, 'val'), transform=val_transform)\n",
        "\n",
        "    # Split validation set into validation and test sets\n",
        "    # Randomly choose test proportion between 30% and 50% each time\n",
        "    test_proportion = random.uniform(0.3, 0.5)  # Random between 30% and 50%\n",
        "\n",
        "    # Generate random seed for truly random splits each time\n",
        "    random_seed = random.randint(1, 10000)  # Different seed each run\n",
        "\n",
        "    print(f\"Using random seed: {random_seed} for dataset splitting\")\n",
        "    print(f\"Randomly selected test proportion: {test_proportion:.2%}\")\n",
        "\n",
        "    val_size = len(val_dataset)\n",
        "    test_size = int(test_proportion * val_size)\n",
        "    val_size = val_size - test_size\n",
        "\n",
        "    # Use the random seed for splitting\n",
        "    val_dataset, test_dataset = torch.utils.data.random_split(\n",
        "        val_dataset, [val_size, test_size],\n",
        "        generator=torch.Generator().manual_seed(random_seed)\n",
        "    )\n",
        "\n",
        "    # Print random split information for reference\n",
        "    print(f\"\\nRandom Split Information (for reproducibility):\")\n",
        "    print(f\"Random Seed Used: {random_seed}\")\n",
        "    print(f\"Test Proportion Used: {test_proportion:.4f}\")\n",
        "\n",
        "    # Create data loaders\n",
        "    batch_size = 32\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "    class_names = train_dataset.classes\n",
        "    print(f\"Classes: {class_names}\")\n",
        "    print(f\"Number of training samples: {len(train_dataset)}\")\n",
        "    print(f\"Number of validation samples: {len(val_dataset)}\")\n",
        "    print(f\"Number of test samples: {len(test_dataset)}\")\n",
        "\n",
        "    # Initialize models\n",
        "    models_dict = {\n",
        "        'Simple CNN': SimpleCNN(num_classes=len(class_names)),\n",
        "        'ResNet-50': create_resnet(num_classes=len(class_names), pretrained=True),\n",
        "        'EfficientNet-B0': create_efficientnet(num_classes=len(class_names), pretrained=True)\n",
        "    }\n",
        "\n",
        "    # Training parameters\n",
        "    num_epochs = 20\n",
        "    learning_rate = 0.001\n",
        "\n",
        "    results = {}\n",
        "    histories = []\n",
        "    model_names = []\n",
        "\n",
        "    # Train each model\n",
        "    for model_name, model in models_dict.items():\n",
        "        print(f\"\\n{'='*50}\")\n",
        "        print(f\"Training {model_name}\")\n",
        "        print(f\"{'='*50}\")\n",
        "\n",
        "        # Setup class weights - penalize missed fractures more heavily\n",
        "        # class_names = ['fractured', 'normal']\n",
        "        # We want to penalize missing fractures (class 0) more than false alarms\n",
        "        class_weights = torch.tensor([2.0, 1.0]).to(device)  # 2x weight for fractured class\n",
        "\n",
        "        # Setup optimizer and scheduler with weighted loss\n",
        "        criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
        "\n",
        "        print(f\"Using class weights: fractured={class_weights[0]:.1f}, normal={class_weights[1]:.1f}\")\n",
        "\n",
        "        # Train model\n",
        "        start_time = time.time()\n",
        "        trained_model, history = train_model(\n",
        "            model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs\n",
        "        )\n",
        "        training_time = time.time() - start_time\n",
        "\n",
        "        # Evaluate model\n",
        "        accuracy, report, cm, preds, labels = evaluate_model(trained_model, test_loader, class_names)\n",
        "\n",
        "        # Store results\n",
        "        results[model_name] = {\n",
        "            'model': trained_model,\n",
        "            'history': history,\n",
        "            'test_accuracy': accuracy,\n",
        "            'classification_report': report,\n",
        "            'confusion_matrix': cm,\n",
        "            'training_time': training_time\n",
        "        }\n",
        "\n",
        "        histories.append(history)\n",
        "        model_names.append(model_name)\n",
        "\n",
        "        print(f\"\\n{model_name} Results:\")\n",
        "        print(f\"Best Validation Accuracy: {history['best_val_acc']:.4f}\")\n",
        "        print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "        print(f\"Training Time: {training_time:.2f} seconds\")\n",
        "\n",
        "        # Save model\n",
        "        torch.save(trained_model.state_dict(), f'{model_name.lower().replace(\" \", \"_\")}_weights.pth')\n",
        "\n",
        "    # Plot comparisons\n",
        "    print(\"\\nGenerating comparison plots...\")\n",
        "    plot_training_history(histories, model_names)\n",
        "\n",
        "    cms = [results[name]['confusion_matrix'] for name in model_names]\n",
        "    plot_confusion_matrices(cms, model_names, class_names)\n",
        "\n",
        "    # Print final comparison\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"FINAL COMPARISON\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    comparison_data = []\n",
        "    for model_name in model_names:\n",
        "        result = results[model_name]\n",
        "        comparison_data.append({\n",
        "            'Model': model_name,\n",
        "            'Best Val Acc': f\"{result['history']['best_val_acc']:.4f}\",\n",
        "            'Test Acc': f\"{result['test_accuracy']:.4f}\",\n",
        "            'Training Time (s)': f\"{result['training_time']:.2f}\",\n",
        "            'Precision (Fractured)': f\"{result['classification_report']['fractured']['precision']:.4f}\",\n",
        "            'Recall (Fractured)': f\"{result['classification_report']['fractured']['recall']:.4f}\",\n",
        "            'F1-Score (Fractured)': f\"{result['classification_report']['fractured']['f1-score']:.4f}\"\n",
        "        })\n",
        "\n",
        "    # Print comparison table\n",
        "    import pandas as pd\n",
        "    df = pd.DataFrame(comparison_data)\n",
        "    print(df.to_string(index=False))\n",
        "\n",
        "    return results\n",
        "\n",
        "# Instructions for running\n",
        "print(\"\"\"\n",
        "INSTRUCTIONS FOR RUNNING THIS CODE:\n",
        "\n",
        "1. Download the dataset from the Google Drive link provided\n",
        "2. Your dataset structure should be:\n",
        "   dataset/\n",
        "   â”œâ”€â”€ train/\n",
        "   â”‚   â”œâ”€â”€ fractured/\n",
        "   â”‚   â””â”€â”€ normal/\n",
        "   â””â”€â”€ val/\n",
        "       â”œâ”€â”€ fractured/\n",
        "       â””â”€â”€ normal/\n",
        "\n",
        "3. Update the 'data_dir' variable in the main() function with your dataset path\n",
        "   Note: The code will automatically split your val folder into validation and test sets\n",
        "\n",
        "4. Run the script:\n",
        "   results = main()\n",
        "\n",
        "5. The script will:\n",
        "   - Train all three models (Simple CNN, ResNet-50, EfficientNet-B0)\n",
        "   - Generate comparison plots\n",
        "   - Print detailed performance metrics\n",
        "   - Save trained model weights\n",
        "\n",
        "EXPECTED OUTCOMES:\n",
        "- EfficientNet should generally perform best due to its efficient architecture\n",
        "- ResNet should perform well with good generalization\n",
        "- Simple CNN may overfit but can serve as a baseline\n",
        "- All models should achieve reasonable accuracy for binary classification\n",
        "\n",
        "For Google Colab:\n",
        "- Upload your dataset to Colab or mount Google Drive\n",
        "- Install required packages: !pip install timm (for additional models if needed)\n",
        "- Make sure GPU is enabled for faster training\n",
        "\"\"\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    results = main()"
      ],
      "metadata": {
        "id": "B-LVpUaJd_Qi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RUN THIS TO EXECUTE WITHOUT AUGMENTATION"
      ],
      "metadata": {
        "id": "gvkTfE8pdVFq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# BASIC TRANSFORMS (NO AUGMENTATION)\n",
        "# =============================================================================\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "print(\"ðŸ”§ Setting up basic transforms (NO AUGMENTATION)\")\n",
        "\n",
        "# Basic transforms for both training and validation (no augmentation)\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "print(\"âœ… Basic transforms created:\")\n",
        "print(\"- Resize to 224x224\")\n",
        "print(\"- Convert to tensor\")\n",
        "print(\"- Normalize with ImageNet stats\")\n",
        "print(\"- NO data augmentation applied\")\n",
        "print(\"=\" * 50)"
      ],
      "metadata": {
        "id": "9KxQE13vdbtg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RUN COMPARISON EXPERIMENTS FOR 2 MODELS"
      ],
      "metadata": {
        "id": "niMBJvWfVPI-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# BLOCK A: EXPERIMENT CONFIGURATION\n",
        "# =============================================================================\n",
        "\n",
        "# EXPERIMENT PARAMETERS - Change these for different runs\n",
        "MODELS_TO_TRAIN = ['Simple CNN', 'ResNet-50']  # Options: 'Simple CNN', 'ResNet-50', 'EfficientNet-B0'\n",
        "BATCH_SIZES = [20, 40]                         # List of batch sizes to test\n",
        "EPOCHS_LIST = [15, 30]                         # List of epoch counts to test\n",
        "LEARNING_RATE = 0.001\n",
        "RANDOM_SEED = 42                               # Set to None for truly random splits\n",
        "\n",
        "# Print experiment configuration\n",
        "print(\"=== EXPERIMENT CONFIGURATION ===\")\n",
        "print(f\"Models to train: {MODELS_TO_TRAIN}\")\n",
        "print(f\"Batch sizes: {BATCH_SIZES}\")\n",
        "print(f\"Epochs: {EPOCHS_LIST}\")\n",
        "print(f\"Learning rate: {LEARNING_RATE}\")\n",
        "print(f\"Random seed: {RANDOM_SEED}\")\n",
        "print(f\"Total experiments: {len(MODELS_TO_TRAIN) * len(BATCH_SIZES) * len(EPOCHS_LIST)}\")\n",
        "print(\"=\" * 40)"
      ],
      "metadata": {
        "id": "y2veXRoLzbqS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# BLOCK B: DATA LOADING AND PREPARATION\n",
        "# =============================================================================\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "from torchvision.datasets import ImageFolder\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "import os\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import pandas as pd\n",
        "\n",
        "# Check device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Data directory\n",
        "data_dir = '/content/dataset/content/bone_data'\n",
        "\n",
        "# Create base datasets (these will be split later for each experiment)\n",
        "base_train_dataset = ImageFolder(os.path.join(data_dir, 'train'), transform=train_transform)\n",
        "base_val_dataset = ImageFolder(os.path.join(data_dir, 'val'), transform=val_transform)\n",
        "\n",
        "# Get class names\n",
        "class_names = base_train_dataset.classes\n",
        "num_classes = len(class_names)\n",
        "print(f\"Classes: {class_names}\")\n",
        "print(f\"Number of classes: {num_classes}\")\n",
        "\n",
        "# Split validation into val and test\n",
        "if RANDOM_SEED is not None:\n",
        "    torch.manual_seed(RANDOM_SEED)\n",
        "    np.random.seed(RANDOM_SEED)\n",
        "    random.seed(RANDOM_SEED)\n",
        "    print(f\"Using fixed random seed: {RANDOM_SEED}\")\n",
        "else:\n",
        "    print(\"Using random splits (different each run)\")\n",
        "\n",
        "test_proportion = 0.4  # 40% for test, 60% for validation\n",
        "val_size = len(base_val_dataset)\n",
        "test_size = int(test_proportion * val_size)\n",
        "val_size = val_size - test_size\n",
        "\n",
        "val_dataset, test_dataset = torch.utils.data.random_split(\n",
        "    base_val_dataset, [val_size, test_size],\n",
        "    generator=torch.Generator().manual_seed(RANDOM_SEED) if RANDOM_SEED else None\n",
        ")\n",
        "\n",
        "print(f\"Dataset sizes - Train: {len(base_train_dataset)}, Val: {len(val_dataset)}, Test: {len(test_dataset)}\")\n"
      ],
      "metadata": {
        "id": "HcRTPScVzfQD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# BLOCK C: MODEL DEFINITIONS\n",
        "# =============================================================================\n",
        "\n",
        "# Simple CNN Architecture\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self, num_classes=2):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d((7, 7)),\n",
        "            nn.Flatten(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256 * 7 * 7, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "def create_resnet(num_classes=2, pretrained=True):\n",
        "    model = models.resnet50(pretrained=pretrained)\n",
        "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "    return model\n",
        "\n",
        "def create_efficientnet(num_classes=2, pretrained=True):\n",
        "    model = models.efficientnet_b0(pretrained=pretrained)\n",
        "    model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
        "    return model\n",
        "\n",
        "# Model factory\n",
        "def create_model(model_name, num_classes):\n",
        "    if model_name == 'Simple CNN':\n",
        "        return SimpleCNN(num_classes=num_classes)\n",
        "    elif model_name == 'ResNet-50':\n",
        "        return create_resnet(num_classes=num_classes)\n",
        "    elif model_name == 'EfficientNet-B0':\n",
        "        return create_efficientnet(num_classes=num_classes)\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown model: {model_name}\")\n",
        "\n",
        "print(\"Models defined successfully!\")"
      ],
      "metadata": {
        "id": "FRQXZNFezmxL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# BLOCK D: TRAINING AND EVALUATION FUNCTIONS\n",
        "# =============================================================================\n",
        "\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs):\n",
        "    model = model.to(device)\n",
        "\n",
        "    train_losses = []\n",
        "    train_accuracies = []\n",
        "    val_losses = []\n",
        "    val_accuracies = []\n",
        "\n",
        "    best_val_acc = 0.0\n",
        "    best_model_wts = model.state_dict().copy()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "        total_samples = 0\n",
        "\n",
        "        pbar = tqdm(train_loader, desc='Training')\n",
        "        for inputs, labels in pbar:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            running_corrects += torch.sum(preds == labels.data)\n",
        "            total_samples += inputs.size(0)\n",
        "\n",
        "            pbar.set_postfix({'Loss': f'{loss.item():.4f}'})\n",
        "\n",
        "        epoch_train_loss = running_loss / total_samples\n",
        "        epoch_train_acc = running_corrects.double() / total_samples\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        val_running_loss = 0.0\n",
        "        val_running_corrects = 0\n",
        "        val_total_samples = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in tqdm(val_loader, desc='Validation'):\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                val_running_loss += loss.item() * inputs.size(0)\n",
        "                val_running_corrects += torch.sum(preds == labels.data)\n",
        "                val_total_samples += inputs.size(0)\n",
        "\n",
        "        epoch_val_loss = val_running_loss / val_total_samples\n",
        "        epoch_val_acc = val_running_corrects.double() / val_total_samples\n",
        "\n",
        "        train_losses.append(epoch_train_loss)\n",
        "        train_accuracies.append(epoch_train_acc.cpu().numpy())\n",
        "        val_losses.append(epoch_val_loss)\n",
        "        val_accuracies.append(epoch_val_acc.cpu().numpy())\n",
        "\n",
        "        print(f'Train Loss: {epoch_train_loss:.4f} Acc: {epoch_train_acc:.4f}')\n",
        "        print(f'Val Loss: {epoch_val_loss:.4f} Acc: {epoch_val_acc:.4f}')\n",
        "\n",
        "        if epoch_val_acc > best_val_acc:\n",
        "            best_val_acc = epoch_val_acc\n",
        "            best_model_wts = model.state_dict().copy()\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "    model.load_state_dict(best_model_wts)\n",
        "\n",
        "    return model, {\n",
        "        'train_losses': train_losses,\n",
        "        'train_accuracies': train_accuracies,\n",
        "        'val_losses': val_losses,\n",
        "        'val_accuracies': val_accuracies,\n",
        "        'best_val_acc': best_val_acc.cpu().numpy()\n",
        "    }\n",
        "\n",
        "def evaluate_model(model, test_loader, class_names):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm(test_loader, desc='Testing'):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    accuracy = np.mean(np.array(all_preds) == np.array(all_labels))\n",
        "    report = classification_report(all_labels, all_preds, target_names=class_names, output_dict=True)\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "\n",
        "    return accuracy, report, cm, all_preds, all_labels\n",
        "\n",
        "print(\"Training and evaluation functions loaded!\")\n"
      ],
      "metadata": {
        "id": "8f7sLuUlz6aY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# BLOCK E: EXPERIMENT EXECUTION\n",
        "# =============================================================================\n",
        "\n",
        "# Store all results\n",
        "all_results = {}\n",
        "experiment_counter = 0\n",
        "total_experiments = len(MODELS_TO_TRAIN) * len(BATCH_SIZES) * len(EPOCHS_LIST)\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"STARTING EXPERIMENTS - {total_experiments} total\")\n",
        "print(f\"{'='*60}\")\n",
        "\n",
        "for model_name in MODELS_TO_TRAIN:\n",
        "    for batch_size in BATCH_SIZES:\n",
        "        for num_epochs in EPOCHS_LIST:\n",
        "            experiment_counter += 1\n",
        "            experiment_id = f\"{model_name}_bs{batch_size}_ep{num_epochs}\"\n",
        "\n",
        "            print(f\"\\n{'='*50}\")\n",
        "            print(f\"EXPERIMENT {experiment_counter}/{total_experiments}\")\n",
        "            print(f\"Model: {model_name}\")\n",
        "            print(f\"Batch Size: {batch_size}\")\n",
        "            print(f\"Epochs: {num_epochs}\")\n",
        "            print(f\"ID: {experiment_id}\")\n",
        "            print(f\"{'='*50}\")\n",
        "\n",
        "            # Create data loaders for this experiment\n",
        "            train_loader = DataLoader(base_train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "            val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "            test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "            # Create model\n",
        "            model = create_model(model_name, num_classes)\n",
        "\n",
        "            # Setup training components\n",
        "            class_weights = torch.tensor([2.0, 1.0]).to(device)\n",
        "            criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "            optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "            scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
        "\n",
        "            # Train model\n",
        "            start_time = time.time()\n",
        "            trained_model, history = train_model(\n",
        "                model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs\n",
        "            )\n",
        "            training_time = time.time() - start_time\n",
        "\n",
        "            # Evaluate model\n",
        "            accuracy, report, cm, preds, labels = evaluate_model(trained_model, test_loader, class_names)\n",
        "\n",
        "            # Store results\n",
        "            all_results[experiment_id] = {\n",
        "                'model_name': model_name,\n",
        "                'batch_size': batch_size,\n",
        "                'num_epochs': num_epochs,\n",
        "                'model': trained_model,\n",
        "                'history': history,\n",
        "                'test_accuracy': accuracy,\n",
        "                'classification_report': report,\n",
        "                'confusion_matrix': cm,\n",
        "                'training_time': training_time\n",
        "            }\n",
        "\n",
        "            print(f\"\\nResults for {experiment_id}:\")\n",
        "            print(f\"Best Val Accuracy: {history['best_val_acc']:.4f}\")\n",
        "            print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "            print(f\"Training Time: {training_time:.2f}s\")\n",
        "\n",
        "            # Save model\n",
        "            torch.save(trained_model.state_dict(), f'{experiment_id}_weights.pth')\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"ALL EXPERIMENTS COMPLETED!\")\n",
        "print(f\"{'='*60}\")\n"
      ],
      "metadata": {
        "id": "u6aMHB2R0C7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# BLOCK F: RESULTS ANALYSIS AND VISUALIZATION\n",
        "# =============================================================================\n",
        "\n",
        "# Create comprehensive results DataFrame\n",
        "results_data = []\n",
        "for exp_id, result in all_results.items():\n",
        "    results_data.append({\n",
        "        'Experiment_ID': exp_id,\n",
        "        'Model': result['model_name'],\n",
        "        'Batch_Size': result['batch_size'],\n",
        "        'Epochs': result['num_epochs'],\n",
        "        'Best_Val_Acc': f\"{result['history']['best_val_acc']:.4f}\",\n",
        "        'Test_Acc': f\"{result['test_accuracy']:.4f}\",\n",
        "        'Training_Time(s)': f\"{result['training_time']:.2f}\",\n",
        "        'Fractured_Precision': f\"{result['classification_report']['fractured']['precision']:.4f}\",\n",
        "        'Fractured_Recall': f\"{result['classification_report']['fractured']['recall']:.4f}\",\n",
        "        'Fractured_F1': f\"{result['classification_report']['fractured']['f1-score']:.4f}\"\n",
        "    })\n",
        "\n",
        "results_df = pd.DataFrame(results_data)\n",
        "print(\"\\nCOMPREHENSIVE RESULTS TABLE:\")\n",
        "print(results_df.to_string(index=False))\n",
        "\n",
        "# Plot comparison charts\n",
        "def plot_experiment_comparison():\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "    # Extract data for plotting\n",
        "    models = [r['model_name'] for r in all_results.values()]\n",
        "    batch_sizes = [r['batch_size'] for r in all_results.values()]\n",
        "    epochs = [r['num_epochs'] for r in all_results.values()]\n",
        "    test_accs = [r['test_accuracy'] for r in all_results.values()]\n",
        "    val_accs = [r['history']['best_val_acc'] for r in all_results.values()]\n",
        "    train_times = [r['training_time'] for r in all_results.values()]\n",
        "\n",
        "    # Create labels for x-axis\n",
        "    labels = [f\"{m}\\nBS:{b} EP:{e}\" for m, b, e in zip(models, batch_sizes, epochs)]\n",
        "\n",
        "    # Test Accuracy comparison\n",
        "    axes[0, 0].bar(range(len(labels)), test_accs, color=['skyblue', 'lightcoral', 'lightgreen'][:len(labels)])\n",
        "    axes[0, 0].set_title('Test Accuracy Comparison')\n",
        "    axes[0, 0].set_ylabel('Accuracy')\n",
        "    axes[0, 0].set_xticks(range(len(labels)))\n",
        "    axes[0, 0].set_xticklabels(labels, rotation=45, ha='right')\n",
        "    axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "    # Validation Accuracy comparison\n",
        "    axes[0, 1].bar(range(len(labels)), val_accs, color=['skyblue', 'lightcoral', 'lightgreen'][:len(labels)])\n",
        "    axes[0, 1].set_title('Best Validation Accuracy Comparison')\n",
        "    axes[0, 1].set_ylabel('Accuracy')\n",
        "    axes[0, 1].set_xticks(range(len(labels)))\n",
        "    axes[0, 1].set_xticklabels(labels, rotation=45, ha='right')\n",
        "    axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "    # Training Time comparison\n",
        "    axes[1, 0].bar(range(len(labels)), train_times, color=['skyblue', 'lightcoral', 'lightgreen'][:len(labels)])\n",
        "    axes[1, 0].set_title('Training Time Comparison')\n",
        "    axes[1, 0].set_ylabel('Time (seconds)')\n",
        "    axes[1, 0].set_xticks(range(len(labels)))\n",
        "    axes[1, 0].set_xticklabels(labels, rotation=45, ha='right')\n",
        "    axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "    # F1 Score for Fractured class\n",
        "    f1_scores = [r['classification_report']['fractured']['f1-score'] for r in all_results.values()]\n",
        "    axes[1, 1].bar(range(len(labels)), f1_scores, color=['skyblue', 'lightcoral', 'lightgreen'][:len(labels)])\n",
        "    axes[1, 1].set_title('F1-Score for Fractured Class')\n",
        "    axes[1, 1].set_ylabel('F1-Score')\n",
        "    axes[1, 1].set_xticks(range(len(labels)))\n",
        "    axes[1, 1].set_xticklabels(labels, rotation=45, ha='right')\n",
        "    axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Plot confusion matrices\n",
        "def plot_all_confusion_matrices():\n",
        "    n_experiments = len(all_results)\n",
        "    cols = min(3, n_experiments)\n",
        "    rows = (n_experiments + cols - 1) // cols\n",
        "\n",
        "    fig, axes = plt.subplots(rows, cols, figsize=(5*cols, 4*rows))\n",
        "    if n_experiments == 1:\n",
        "        axes = [axes]\n",
        "    elif rows == 1:\n",
        "        axes = [axes]\n",
        "    else:\n",
        "        axes = axes.flatten()\n",
        "\n",
        "    for i, (exp_id, result) in enumerate(all_results.items()):\n",
        "        if i < len(axes):\n",
        "            sns.heatmap(result['confusion_matrix'], annot=True, fmt='d', cmap='Blues',\n",
        "                       xticklabels=class_names, yticklabels=class_names, ax=axes[i])\n",
        "            axes[i].set_title(f'{exp_id}\\nTest Acc: {result[\"test_accuracy\"]:.4f}')\n",
        "            axes[i].set_xlabel('Predicted')\n",
        "            axes[i].set_ylabel('Actual')\n",
        "\n",
        "    # Hide unused subplots\n",
        "    for i in range(len(all_results), len(axes)):\n",
        "        axes[i].set_visible(False)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Generate all plots\n",
        "print(\"\\nGenerating comparison plots...\")\n",
        "plot_experiment_comparison()\n",
        "plot_all_confusion_matrices()\n",
        "\n",
        "print(f\"\\nEXPERIMENT COMPLETE!\")\n",
        "print(f\"Results stored in 'all_results' dictionary\")\n",
        "print(f\"Results DataFrame: 'results_df'\")\n",
        "print(f\"Model weights saved as: [experiment_id]_weights.pth\")"
      ],
      "metadata": {
        "id": "behh9aoC0JTE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LIME EXPLANATION"
      ],
      "metadata": {
        "id": "t4G4Hp0PZgoR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# INSTALL REQUIRED PACKAGES FOR MODEL EXPLANATION\n",
        "# =============================================================================\n",
        "\n",
        "# Run this cell first before running the explanation block!\n",
        "\n",
        "print(\"ðŸ“¦ Installing required packages for model explanation...\")\n",
        "\n",
        "# Install LIME\n",
        "!pip install lime\n",
        "\n",
        "# Install OpenCV for image processing\n",
        "!pip install opencv-python\n",
        "\n",
        "# Install scikit-image (usually included but just in case)\n",
        "!pip install scikit-image\n",
        "\n",
        "print(\"âœ… Installation complete!\")\n",
        "print()\n",
        "print(\"ðŸ“‹ Installed packages:\")\n",
        "print(\"- lime: For Local Interpretable Model-agnostic Explanations\")\n",
        "print(\"- opencv-python: For image processing in GradCAM\")\n",
        "print(\"- scikit-image: For image segmentation in LIME\")\n",
        "print()\n",
        "print(\"ðŸš€ You can now run the Model Explanation block!\")\n",
        "\n",
        "# =============================================================================\n",
        "# LIME MODEL EXPLANATION - FRACTURE DETECTION ANALYSIS\n",
        "# =============================================================================\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import lime\n",
        "from lime import lime_image\n",
        "from skimage.segmentation import mark_boundaries\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms\n",
        "import os\n",
        "import random"
      ],
      "metadata": {
        "id": "610GndgcnleH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# DEBUG MODEL FILES AND FIX LOADING\n",
        "# =============================================================================\n",
        "\n",
        "import os\n",
        "\n",
        "print(\"ðŸ” Checking for saved model files...\")\n",
        "\n",
        "# Check what .pth files exist\n",
        "pth_files = [f for f in os.listdir('.') if f.endswith('.pth')]\n",
        "\n",
        "if pth_files:\n",
        "    print(\"âœ… Found model files:\")\n",
        "    for file in pth_files:\n",
        "        print(f\"   - {file}\")\n",
        "else:\n",
        "    print(\"âŒ No .pth files found!\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "\n",
        "# Check if all_results exists and contains models\n",
        "if 'all_results' in globals():\n",
        "    print(\"âœ… all_results variable exists!\")\n",
        "    print(f\"ðŸ“Š Found {len(all_results)} trained models:\")\n",
        "    for exp_id, result in all_results.items():\n",
        "        print(f\"   - {exp_id}\")\n",
        "\n",
        "    # Get the best performing model (you said Simple CNN bs20 ep15 was best)\n",
        "    best_exp_id = None\n",
        "    best_acc = 0\n",
        "\n",
        "    for exp_id, result in all_results.items():\n",
        "        test_acc = result['test_accuracy']\n",
        "        if test_acc > best_acc:\n",
        "            best_acc = test_acc\n",
        "            best_exp_id = exp_id\n",
        "\n",
        "    print(f\"\\nðŸ† Best performing model: {best_exp_id} (Acc: {best_acc:.4f})\")\n",
        "\n",
        "else:\n",
        "    print(\"âŒ all_results not found - Block E may not have completed successfully\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)"
      ],
      "metadata": {
        "id": "dG9_JBHqoyy4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# FIXED MODEL EXPLANATION BLOCK (Uses all_results instead of file loading)\n",
        "# =============================================================================\n",
        "\n",
        "def load_best_model_from_results():\n",
        "    \"\"\"Load best model directly from all_results instead of file\"\"\"\n",
        "\n",
        "    if 'all_results' not in globals():\n",
        "        print(\"âŒ Error: all_results not found. Please run Block E first.\")\n",
        "        return None\n",
        "\n",
        "    # Find best model from results\n",
        "    best_exp_id = None\n",
        "    best_acc = 0\n",
        "\n",
        "    for exp_id, result in all_results.items():\n",
        "        test_acc = result['test_accuracy']\n",
        "        if test_acc > best_acc:\n",
        "            best_acc = test_acc\n",
        "            best_exp_id = exp_id\n",
        "\n",
        "    print(f\"ðŸ† Loading best model: {best_exp_id}\")\n",
        "    print(f\"ðŸ“Š Test Accuracy: {best_acc:.4f}\")\n",
        "\n",
        "    # Get the trained model directly from results\n",
        "    best_model = all_results[best_exp_id]['model']\n",
        "    best_model.eval()  # Set to evaluation mode\n",
        "\n",
        "    return best_model, best_exp_id\n",
        "\n",
        "# Try to load the best model\n",
        "if 'all_results' in globals():\n",
        "    print(\"ðŸš€ Loading best model from training results...\")\n",
        "    try:\n",
        "        best_model, best_model_id = load_best_model_from_results()\n",
        "        print(f\"âœ… Successfully loaded: {best_model_id}\")\n",
        "        print(\"ðŸŽ¯ Ready for explanation analysis!\")\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Error loading model: {e}\")\n",
        "else:\n",
        "    print(\"âš ï¸  Please run Block E (training) first to generate models.\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ðŸ“‹ NEXT STEPS:\")\n",
        "print(\"1. If models loaded successfully âœ… â†’ Run the explanation analysis\")\n",
        "print(\"2. If no models found âŒ â†’ Re-run Blocks C, D, E in sequence\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "id": "x6V-ah3Lo_GQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# LIME MODEL EXPLANATION - FRACTURE DETECTION ANALYSIS\n",
        "# =============================================================================\n",
        "\n",
        "print(\"ðŸ”¬ LIME Explanation Analysis for Fracture Detection\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Configuration\n",
        "NUM_SAMPLES = 6  # Number of test images to explain\n",
        "LIME_SAMPLES = 1500  # Number of samples for LIME (higher = more accurate)\n",
        "NUM_FEATURES = 15  # Number of superpixels to show in explanation\n",
        "\n",
        "# =============================================================================\n",
        "# LIME PREDICTION FUNCTION\n",
        "# =============================================================================\n",
        "\n",
        "def predict_fn_for_lime(images):\n",
        "    \"\"\"Optimized prediction function for LIME\"\"\"\n",
        "\n",
        "    # Handle single image\n",
        "    if len(images.shape) == 3:\n",
        "        images = images[np.newaxis, ...]\n",
        "\n",
        "    # Normalization transform\n",
        "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "\n",
        "    predictions = []\n",
        "    best_model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for img in images:\n",
        "            # Convert numpy array to tensor and normalize\n",
        "            if img.max() > 1.0:  # If image is in [0, 255] range\n",
        "                img = img / 255.0\n",
        "\n",
        "            img_tensor = torch.FloatTensor(img).permute(2, 0, 1)  # HWC to CHW\n",
        "            img_tensor = normalize(img_tensor).unsqueeze(0).to(device)\n",
        "\n",
        "            # Get prediction\n",
        "            output = best_model(img_tensor)\n",
        "            prob = F.softmax(output, dim=1)\n",
        "            predictions.append(prob.cpu().numpy()[0])\n",
        "\n",
        "    return np.array(predictions)\n",
        "\n",
        "# =============================================================================\n",
        "# SAMPLE SELECTION AND ANALYSIS\n",
        "# =============================================================================\n",
        "\n",
        "def get_diverse_samples(num_samples=6):\n",
        "    \"\"\"Get diverse sample images including both classes and confidence levels\"\"\"\n",
        "\n",
        "    print(f\"ðŸŽ¯ Selecting {num_samples} diverse test images...\")\n",
        "\n",
        "    # Get predictions for all test images first\n",
        "    test_predictions = []\n",
        "    test_confidences = []\n",
        "    test_indices = []\n",
        "\n",
        "    best_model.eval()\n",
        "    with torch.no_grad():\n",
        "        for idx in range(min(100, len(test_dataset))):  # Check first 100 images\n",
        "            # Get image\n",
        "            img_path = test_dataset.dataset.samples[test_dataset.indices[idx]][0]\n",
        "            img = Image.open(img_path).convert('RGB').resize((224, 224))\n",
        "\n",
        "            # Transform for model\n",
        "            img_tensor = val_transform(img).unsqueeze(0).to(device)\n",
        "\n",
        "            # Predict\n",
        "            output = best_model(img_tensor)\n",
        "            prob = F.softmax(output, dim=1)\n",
        "            pred_class = torch.argmax(prob, dim=1).item()\n",
        "            confidence = prob[0][pred_class].item()\n",
        "\n",
        "            test_predictions.append(pred_class)\n",
        "            test_confidences.append(confidence)\n",
        "            test_indices.append(idx)\n",
        "\n",
        "    # Select diverse samples\n",
        "    selected_indices = []\n",
        "\n",
        "    # Get samples from each class\n",
        "    for class_idx in [0, 1]:  # normal, fractured\n",
        "        class_samples = [(i, conf) for i, (pred, conf) in enumerate(zip(test_predictions, test_confidences))\n",
        "                        if pred == class_idx]\n",
        "\n",
        "        if class_samples:\n",
        "            # Sort by confidence and pick diverse samples\n",
        "            class_samples.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "            # Pick high and medium confidence samples\n",
        "            samples_to_pick = min(num_samples // 2, len(class_samples))\n",
        "            for i in range(samples_to_pick):\n",
        "                idx = class_samples[i * (len(class_samples) // samples_to_pick)][0]\n",
        "                selected_indices.append(test_indices[idx])\n",
        "\n",
        "    # Fill remaining slots randomly if needed\n",
        "    while len(selected_indices) < num_samples and len(selected_indices) < len(test_indices):\n",
        "        remaining = [i for i in test_indices if i not in selected_indices]\n",
        "        if remaining:\n",
        "            selected_indices.append(random.choice(remaining))\n",
        "\n",
        "    return selected_indices[:num_samples]\n",
        "\n",
        "def explain_with_lime():\n",
        "    \"\"\"Generate comprehensive LIME explanations\"\"\"\n",
        "\n",
        "    print(\"ðŸš€ Starting LIME explanation analysis...\")\n",
        "\n",
        "    # Get diverse sample images\n",
        "    sample_indices = get_diverse_samples(NUM_SAMPLES)\n",
        "\n",
        "    # Initialize LIME explainer\n",
        "    explainer = lime_image.LimeImageExplainer(random_state=42)\n",
        "\n",
        "    # Create figure\n",
        "    fig, axes = plt.subplots(NUM_SAMPLES, 3, figsize=(15, 5*NUM_SAMPLES))\n",
        "    fig.suptitle(f'LIME Explanations: {best_model_id}', fontsize=16, fontweight='bold')\n",
        "\n",
        "    explanations_data = []\n",
        "\n",
        "    for i, sample_idx in enumerate(sample_indices):\n",
        "        print(f\"ðŸ“¸ Analyzing image {i+1}/{NUM_SAMPLES}...\")\n",
        "\n",
        "        # Load image\n",
        "        img_path = test_dataset.dataset.samples[test_dataset.indices[sample_idx]][0]\n",
        "        img = Image.open(img_path).convert('RGB').resize((224, 224))\n",
        "        img_array = np.array(img)\n",
        "\n",
        "        # Get true label\n",
        "        true_label = test_dataset.dataset.samples[test_dataset.indices[sample_idx]][1]\n",
        "\n",
        "        # Get model prediction\n",
        "        img_tensor = val_transform(img).unsqueeze(0).to(device)\n",
        "        with torch.no_grad():\n",
        "            output = best_model(img_tensor)\n",
        "            probabilities = F.softmax(output, dim=1)\n",
        "            predicted_class = torch.argmax(probabilities, dim=1).item()\n",
        "            confidence = probabilities[0][predicted_class].item()\n",
        "\n",
        "        # Generate LIME explanation\n",
        "        print(f\"   ðŸ”¬ Generating LIME explanation (using {LIME_SAMPLES} samples)...\")\n",
        "        explanation = explainer.explain_instance(\n",
        "            img_array,\n",
        "            predict_fn_for_lime,\n",
        "            top_labels=2,\n",
        "            hide_color=0,\n",
        "            num_samples=LIME_SAMPLES,\n",
        "            random_seed=42\n",
        "        )\n",
        "\n",
        "        # Get explanation for predicted class\n",
        "        temp, mask = explanation.get_image_and_mask(\n",
        "            predicted_class,\n",
        "            positive_only=False,\n",
        "            num_features=NUM_FEATURES,\n",
        "            hide_rest=False\n",
        "        )\n",
        "\n",
        "        # Calculate explanation statistics\n",
        "        positive_pixels = np.sum(mask > 0)\n",
        "        negative_pixels = np.sum(mask < 0)\n",
        "        total_pixels = mask.size\n",
        "\n",
        "        # Store explanation data\n",
        "        explanations_data.append({\n",
        "            'image_idx': i+1,\n",
        "            'true_label': class_names[true_label],\n",
        "            'predicted_label': class_names[predicted_class],\n",
        "            'confidence': confidence,\n",
        "            'correct': true_label == predicted_class,\n",
        "            'positive_pixels': positive_pixels,\n",
        "            'negative_pixels': negative_pixels,\n",
        "            'explanation_coverage': (positive_pixels + negative_pixels) / total_pixels\n",
        "        })\n",
        "\n",
        "        # Plot results\n",
        "        if NUM_SAMPLES == 1:\n",
        "            axes = [axes]\n",
        "\n",
        "        # Original image\n",
        "        axes[i][0].imshow(img_array)\n",
        "        axes[i][0].set_title(f'Original X-ray #{i+1}\\n'\n",
        "                           f'True: {class_names[true_label]}\\n'\n",
        "                           f'Pred: {class_names[predicted_class]}\\n'\n",
        "                           f'Confidence: {confidence:.1%}')\n",
        "        axes[i][0].axis('off')\n",
        "\n",
        "        # LIME explanation\n",
        "        axes[i][1].imshow(mark_boundaries(temp / 255.0, mask, color=(1, 1, 0), mode='thick'))\n",
        "        axes[i][1].set_title(f'LIME Explanation\\n'\n",
        "                           f'Green=Supports \"{class_names[predicted_class]}\"\\n'\n",
        "                           f'Red=Opposes \"{class_names[predicted_class]}\"')\n",
        "        axes[i][1].axis('off')\n",
        "\n",
        "        # Positive features only\n",
        "        temp_pos, mask_pos = explanation.get_image_and_mask(\n",
        "            predicted_class,\n",
        "            positive_only=True,\n",
        "            num_features=NUM_FEATURES//2,\n",
        "            hide_rest=False\n",
        "        )\n",
        "\n",
        "        axes[i][2].imshow(mark_boundaries(temp_pos / 255.0, mask_pos, color=(0, 1, 0), mode='thick'))\n",
        "        axes[i][2].set_title(f'Supporting Evidence Only\\n'\n",
        "                           f'Areas that support\\n'\n",
        "                           f'\"{class_names[predicted_class]}\" diagnosis')\n",
        "        axes[i][2].axis('off')\n",
        "\n",
        "        # Print detailed analysis\n",
        "        print(f\"\"\"\n",
        "        ðŸ“Š Image {i+1} Analysis:\n",
        "        - True Label: {class_names[true_label]}\n",
        "        - Predicted: {class_names[predicted_class]} ({confidence:.1%} confidence)\n",
        "        - Correct: {'âœ… Yes' if true_label == predicted_class else 'âŒ No'}\n",
        "        - Supporting pixels: {positive_pixels:,} ({positive_pixels/total_pixels:.1%})\n",
        "        - Opposing pixels: {negative_pixels:,} ({negative_pixels/total_pixels:.1%})\n",
        "        \"\"\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return explanations_data, explainer\n",
        "\n",
        "# =============================================================================\n",
        "# MEDICAL ANALYSIS FRAMEWORK\n",
        "# =============================================================================\n",
        "\n",
        "def analyze_medical_validity(explanations_data):\n",
        "    \"\"\"Analyze the medical validity of LIME explanations\"\"\"\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"ðŸ¥ MEDICAL VALIDITY ANALYSIS\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Summary statistics\n",
        "    total_images = len(explanations_data)\n",
        "    correct_predictions = sum(1 for exp in explanations_data if exp['correct'])\n",
        "    avg_confidence = np.mean([exp['confidence'] for exp in explanations_data])\n",
        "    avg_coverage = np.mean([exp['explanation_coverage'] for exp in explanations_data])\n",
        "\n",
        "    print(f\"\"\"\n",
        "    ðŸ“Š SUMMARY STATISTICS:\n",
        "    - Total images analyzed: {total_images}\n",
        "    - Correct predictions: {correct_predictions}/{total_images} ({correct_predictions/total_images:.1%})\n",
        "    - Average confidence: {avg_confidence:.1%}\n",
        "    - Average explanation coverage: {avg_coverage:.1%}\n",
        "    \"\"\")\n",
        "\n",
        "    print(\"\"\"\n",
        "    ðŸ” MEDICAL INTERPRETATION GUIDELINES:\n",
        "\n",
        "    âœ… GOOD SIGNS (Model focusing on relevant anatomy):\n",
        "    - Highlighted regions on bone structures\n",
        "    - Focus on cortical bone lines and edges\n",
        "    - Attention to joint spaces and alignment\n",
        "    - Areas where fractures commonly occur (distal radius, metacarpals, phalanges)\n",
        "    - Density variations in bone tissue\n",
        "\n",
        "    âŒ CONCERNING SIGNS (Model might be using shortcuts):\n",
        "    - Focus on text, labels, or annotations\n",
        "    - Attention to medical equipment or positioning aids\n",
        "    - Background artifacts or non-anatomical features\n",
        "    - Patient identifiers or technical markers\n",
        "\n",
        "    ðŸ“ EVALUATION CRITERIA:\n",
        "    1. Anatomical Relevance: Do highlighted areas correspond to bone structures?\n",
        "    2. Medical Logic: Do the explanations align with fracture detection principles?\n",
        "    3. Consistency: Are explanations consistent across similar cases?\n",
        "    4. Clinical Utility: Would these explanations help a radiologist?\n",
        "    \"\"\")\n",
        "\n",
        "    # Detailed analysis for each prediction type\n",
        "    fractured_explanations = [exp for exp in explanations_data if exp['predicted_label'] == 'fractured']\n",
        "    normal_explanations = [exp for exp in explanations_data if exp['predicted_label'] == 'normal']\n",
        "\n",
        "    if fractured_explanations:\n",
        "        print(f\"\\nðŸ¦´ FRACTURED PREDICTIONS ({len(fractured_explanations)} images):\")\n",
        "        for exp in fractured_explanations:\n",
        "            status = \"âœ…\" if exp['correct'] else \"âŒ\"\n",
        "            print(f\"   {status} Image {exp['image_idx']}: {exp['confidence']:.1%} confidence\")\n",
        "\n",
        "    if normal_explanations:\n",
        "        print(f\"\\nâœ… NORMAL PREDICTIONS ({len(normal_explanations)} images):\")\n",
        "        for exp in normal_explanations:\n",
        "            status = \"âœ…\" if exp['correct'] else \"âŒ\"\n",
        "            print(f\"   {status} Image {exp['image_idx']}: {exp['confidence']:.1%} confidence\")\n",
        "\n",
        "# =============================================================================\n",
        "# EXECUTION\n",
        "# =============================================================================\n",
        "\n",
        "if 'best_model' in globals() and 'best_model_id' in globals():\n",
        "    print(f\"ðŸŽ¯ Using model: {best_model_id}\")\n",
        "    print(f\"ðŸ“Š Device: {device}\")\n",
        "\n",
        "    # Run LIME analysis\n",
        "    explanations_data, lime_explainer = explain_with_lime()\n",
        "\n",
        "    # Analyze medical validity\n",
        "    analyze_medical_validity(explanations_data)\n",
        "\n",
        "    print(f\"\"\"\n",
        "    âœ… LIME ANALYSIS COMPLETE!\n",
        "\n",
        "    ðŸ“‹ FOR YOUR REPORT, INCLUDE:\n",
        "    1. The LIME visualization plots showing original images and explanations\n",
        "    2. Discussion of whether highlighted regions are anatomically relevant\n",
        "    3. Analysis of model focus on bone structures vs artifacts\n",
        "    4. Medical validity assessment of the explanations\n",
        "\n",
        "    ðŸ’¡ KEY POINTS TO DISCUSS:\n",
        "    - LIME provides local explanations for individual predictions\n",
        "    - Green regions support the predicted class, red regions oppose it\n",
        "    - Model interpretability is crucial for medical AI adoption\n",
        "    - Explanations should align with radiological knowledge\n",
        "    \"\"\")\n",
        "\n",
        "else:\n",
        "    print(\"âŒ Error: Best model not loaded. Please run the model loading block first.\")"
      ],
      "metadata": {
        "id": "SvZkts2z9gJM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}