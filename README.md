![Build Status](https://img.shields.io/badge/build-passing-brightgreen.svg)
![Python Version](https://img.shields.io/badge/python-3.8%2B-blue.svg)
![PyTorch](https://img.shields.io/badge/PyTorch-2.0%2B-orange.svg)
![License](https://img.shields.io/badge/license-MIT-green.svg)
![Medical AI](https://img.shields.io/badge/Medical-AI-red.svg)
![Contributions Welcome](https://img.shields.io/badge/contributions-welcome-brightgreen.svg)

# FructureBOT - X-ray Fracture Detection with Deep Learning

A comprehensive deep learning project for automated fracture detection in X-ray images, featuring extensive model comparisons, hyperparameter experiments, and explainable AI techniques for medical diagnosis.

## ðŸ¥ Project Overview

This project implements and systematically compares multiple state-of-the-art deep learning architectures for binary fracture classification in X-ray images. The goal is to assist medical professionals in quickly and accurately identifying bone fractures through automated analysis with explainable predictions.

### ðŸŽ¯ Key Features

- **Multi-Architecture Comparison**: Custom CNN, ResNet-50, and EfficientNet-B0
- **Comprehensive Experiments**: Multiple batch sizes, epochs, and data augmentation strategies
- **Medical AI Focus**: Class-weighted training prioritizing fracture detection (2:1 weight ratio)
- **Explainable AI**: LIME (Local Interpretable Model-agnostic Explanations) for medical validity
- **Professional Structure**: Modular code blocks with extensive documentation
- **Automated Evaluation**: Confusion matrices, classification reports, and performance metrics

## ðŸ—ï¸ Architecture Comparison

### Models Implemented:

1. **Custom CNN** - 4-layer architecture with BatchNorm and Dropout
   - Features: 32â†’64â†’128â†’256 filters with MaxPooling
   - Classifier: AdaptiveAvgPool + 512-unit dense layer
   - Purpose: Baseline comparison and interpretability

2. **ResNet-50** - Deep residual network with transfer learning
   - Pre-trained on ImageNet, fine-tuned for fracture detection
   - Modified final layer for binary classification
   - Purpose: State-of-the-art performance with skip connections

3. **EfficientNet-B0** - Compound scaling optimization
   - Pre-trained weights with efficient architecture
   - Optimal balance of accuracy, speed, and model size
   - Purpose: Modern efficient architecture benchmark

## ðŸ“Š Dataset & Preprocessing

- **Source**: Medical X-ray images from bone fracture dataset
- **Classes**: Fractured vs Normal (non-fractured) bones
- **Image Size**: 224Ã—224 pixels (standard CNN input)
- **Normalization**: ImageNet statistics for transfer learning compatibility
- **Split Strategy**: Random validation/test splits (60/40) with configurable seeds

### Data Augmentation (Configurable):
- Random horizontal flip (50% probability)
- Random rotation (Â±10 degrees)
- Color jitter (brightness & contrast Â±20%)
- Controlled toggle for augmentation on/off experiments

## ðŸ”¬ Experimental Design

The project includes comprehensive hyperparameter experiments:

### Experiment Variables:
- **Models**: Simple CNN, ResNet-50, EfficientNet-B0
- **Batch Sizes**: [20, 40] (configurable)
- **Epochs**: [15, 30] (configurable)
- **Learning Rate**: 0.001 (Adam optimizer)
- **Data Augmentation**: On/Off toggle
- **Class Weights**: 2:1 (fractured:normal) for medical priorities

### Medical-Focused Training:
- **Weighted Loss Function**: Penalizes missed fractures 2Ã— more than false positives
- **Early Stopping**: Based on validation accuracy
- **Learning Rate Scheduling**: StepLR with Î³=0.1 every 7 epochs

## ðŸ“ˆ Results & Performance

The notebook generates comprehensive performance analysis including:

### Metrics Tracked:
- **Accuracy**: Training, validation, and test accuracy
- **Precision/Recall**: Specifically for fracture detection
- **F1-Score**: Balanced metric for medical applications
- **Confusion Matrices**: Visual error analysis
- **Training Time**: Efficiency comparison

### Visualization Dashboard:
- Training/validation loss curves
- Accuracy progression over epochs
- Side-by-side confusion matrices
- Model comparison charts
- LIME explanation visualizations

## ðŸ” Explainable AI (XAI)

### LIME Integration:
- **Local Explanations**: Individual prediction interpretability
- **Medical Validation**: Anatomical relevance analysis
- **Visual Explanations**: Highlighted regions supporting decisions
- **Clinical Guidelines**: Framework for medical interpretation

### Medical Interpretation Framework:
- âœ… **Good Signs**: Focus on bone structures, cortical lines, joint spaces
- âŒ **Concerning Signs**: Attention to text, equipment, or artifacts
- ðŸ“Š **Evaluation Criteria**: Anatomical relevance, medical logic, consistency

## ðŸ› ï¸ Installation & Setup

### Prerequisites
```bash
Python 3.8+
PyTorch 2.0+
torchvision
CUDA-capable GPU (recommended)
```

### Required Packages
```bash
# Core ML libraries
pip install torch torchvision
pip install numpy pandas matplotlib seaborn
pip install scikit-learn tqdm

# Image processing and XAI
pip install Pillow opencv-python
pip install lime scikit-image

# Jupyter environment
pip install jupyter ipykernel

# Data handling
pip install gdown  # For Google Drive dataset download
```

### Google Colab Setup
```python
# Install in Colab
!pip install lime opencv-python scikit-image gdown

# Enable GPU
# Runtime â†’ Change runtime type â†’ Hardware accelerator: GPU
```

## ðŸš€ Usage


### Dataset Setup
The notebook automatically downloads and processes the dataset:
```python
# Google Drive dataset download
file_id = '1pfyAN5XE4ULgnx9NHfMCgw9QK6KCee_l'
# Automatic extraction and folder renaming
```

### Experiment Configuration
```python
# Modify these variables for different experiments:
MODELS_TO_TRAIN = ['Simple CNN', 'ResNet-50', 'EfficientNet-B0']
BATCH_SIZES = [16, 32, 64]
EPOCHS_LIST = [10, 20, 30]
LEARNING_RATE = 0.001
RANDOM_SEED = 42  # For reproducibility
```

## ðŸ“ Project Structure

```
FructureBOT/
â”œâ”€â”€ README.md                           # This comprehensive guide
â”œâ”€â”€ requirements.txt                    # Python dependencies
â”œâ”€â”€ .gitignore                         # Git ignore rules
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ AI_PROJECT_REFINED.ipynb      # Main analysis notebook
â”œâ”€â”€ models/                            # Saved model weights
â”‚   â”œâ”€â”€ simple_cnn_bs20_ep15_weights.pth
â”‚   â”œâ”€â”€ resnet-50_bs20_ep15_weights.pth
â”‚   â””â”€â”€ efficientnet-b0_bs40_ep30_weights.pth
â”œâ”€â”€ results/                           # Experimental results
â”‚   â”œâ”€â”€ training_curves/
â”‚   â”œâ”€â”€ confusion_matrices/
â”‚   â”œâ”€â”€ lime_explanations/
â”‚   â””â”€â”€ performance_comparison.csv
â”œâ”€â”€ docs/                              # Documentation
â”‚   â”œâ”€â”€ methodology.md
â”‚   â”œâ”€â”€ medical_guidelines.md
â”‚   â””â”€â”€ experiment_log.md
â””â”€â”€ data/                             # Dataset (if included)
    â”œâ”€â”€ train/
    â”‚   â”œâ”€â”€ fractured/
    â”‚   â””â”€â”€ normal/
    â””â”€â”€ val/
        â”œâ”€â”€ fractured/
        â””â”€â”€ normal/
```

## ðŸ”¬ Methodology

### Training Pipeline:
1. **Data Preparation**: Automatic download, extraction, and preprocessing
2. **Model Initialization**: Architecture-specific setup with transfer learning
3. **Training Loop**: Progress tracking with tqdm, validation monitoring
4. **Evaluation**: Comprehensive metrics calculation and visualization
5. **Model Saving**: Automatic weight persistence for each experiment

### Medical AI Considerations:
- **Class Imbalance**: Addressed through weighted loss functions
- **Clinical Relevance**: Emphasis on fracture recall over overall accuracy
- **Interpretability**: LIME explanations for clinical decision support
- **Validation**: Medical interpretation guidelines for AI explanations

## ðŸ“Š Key Findings & Insights

Based on experimental results:

### Model Performance Insights:
- **Transfer Learning Advantage**: Pre-trained models (ResNet, EfficientNet) typically outperform custom CNN
- **Batch Size Impact**: Smaller batches (20) often provide better generalization
- **Augmentation Benefits**: Data augmentation generally improves robustness
- **Training Efficiency**: EfficientNet offers best accuracy-to-time ratio

### Medical AI Insights:
- **Explainability Matters**: LIME reveals whether models focus on anatomically relevant features
- **Class Weighting Crucial**: 2:1 weighting significantly improves fracture detection recall
- **Clinical Validation**: Manual review of LIME explanations essential for medical deployment

## ðŸ”„ Future Improvements

- [ ] **Advanced Architectures**: Vision Transformers (ViT), DenseNet variants
- [ ] **Multi-Class Extension**: Specific fracture type classification
- [ ] **Ensemble Methods**: Combining multiple model predictions
- [ ] **Advanced XAI**: GradCAM, Integrated Gradients, SHAP
- [ ] **Clinical Integration**: DICOM support, radiologist workflow integration
- [ ] **Deployment Pipeline**: Web interface, mobile application, hospital system API
- [ ] **Larger Datasets**: Multi-institutional validation
- [ ] **Real-time Processing**: Optimization for clinical deployment

## ðŸ“š Technical Documentation

### Block Structure:
- **Block 0**: Environment setup and dataset cleaning
- **Block A**: Experiment configuration and parameters
- **Block B**: Data loading and preprocessing pipeline
- **Block C**: Model architecture definitions
- **Block D**: Training and evaluation functions
- **Block E**: Comprehensive experiment execution
- **Block F**: Results analysis and visualization
- **LIME Block**: Explainable AI implementation

### Design Patterns:
- **Modular Architecture**: Each block serves specific purpose
- **Configuration-Driven**: Easy parameter modification
- **Comprehensive Logging**: Detailed progress and results tracking
- **Medical Focus**: Class weighting and clinical metrics priority

## ðŸ¥ Medical Validation Guidelines

### Anatomical Focus Areas:
- âœ… Cortical bone lines and discontinuities
- âœ… Joint spaces and alignment
- âœ… Bone density variations
- âœ… Common fracture locations (distal radius, metacarpals)

### Red Flags for AI Explanations:
- âŒ Focus on text annotations or labels
- âŒ Attention to medical equipment
- âŒ Background artifacts or positioning aids
- âŒ Non-anatomical features

## ðŸ¤ Contributing

Contributions welcome! Please focus on:
- **Medical Accuracy**: Ensure clinical relevance
- **Code Quality**: Follow medical AI best practices
- **Documentation**: Clear methodology description
- **Validation**: Thorough testing with medical datasets

## ðŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ðŸ™ Acknowledgments

- **Medical Community**: For fracture detection clinical guidelines
- **PyTorch Team**: For deep learning framework
- **LIME Developers**: For explainable AI capabilities
- **Dataset Contributors**: For providing medical imaging data

## ðŸ“ž Contact & Citation

**Author**: Kostas Plomaritis  
**Institution**: [AUTh University - BioMedical Engineering]  
**Email**: [kplomari@gmail.com]  
**LinkedIn**: [-]

**Project Repository**: [https://github.com/kostas-g33579/FructureBOT](https://github.com/kostas-g33579/FructureBOT)

### Citation
```bibtex
@software{fracture_bot_2025,
  title={FructureBOT: Deep Learning for X-ray Fracture Detection with Explainable AI},
  author={Kostas G},
  year={2025},
  url={https://github.com/kostas-g33579/FructureBOT}
}
```

---

â­ **If this project helps your research or clinical work, please give it a star!** â­

> **Medical Disclaimer**: This tool is for research purposes only and should not replace professional medical diagnosis. Always consult qualified healthcare professionals for medical decisions.
